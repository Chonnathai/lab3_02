{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Predicting shots made per game by Kobe Bryant\n",
    "\n",
    "_Authors: Kiefer Katovich (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "In this lab you'll be using regularized regression penalties Ridge, Lasso, and Elastic Net to try and predict how many shots Kobe Bryant made per game in his career.\n",
    "\n",
    "The Kobe shots dataset has hundreds of columns representing different characteristics of each basketball game. Fitting an ordinary linear regression using every predictor would dramatically overfit the model considering the limited number of observations (games) we have available. Furthermore, many of the predictors have significant multicollinearity. \n",
    "\n",
    "\n",
    "**Warning:** Some of these calculations are computationally expensive and may take a while to execute.  It may be worth while to only use a portion of the data to perform these calculations, especially if you have experienced kernel issues in the past.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Load packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import patsy\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kobe = pd.read_csv('../datasets/kobe_superwide_games.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2. Examine the data\n",
    "\n",
    "- How many columns are there?\n",
    "- Examine what the observations (rows) and columns represent.\n",
    "- Why is this data that regularization might be particularly useful for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. Make predictor and target variables. Standardize the predictors.\n",
    "\n",
    "Why is normalization necessary for regularized regressions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:<br>\n",
    "Standardization is necessary for regularized regression because the beta values for each predictor variable must be on the same scale. If betas are different sizes just because of the scale of predictor variables the regularization term can't determine which betas are more/less important based on their size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Perform `train-test-split` on your data to create two data sets - a training data set and a validation(test) data set\n",
    "* Use the `sklearn.preprocessing` class `StandardScaler` to standardize the predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = \n",
    "X = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform train-test-split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the StandardScaler object\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "# Scale your X features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4. Build a linear regression predicting `SHOTS_MADE` from the rest of the columns.\n",
    "\n",
    "* Instantiate your linear regresesion model\n",
    "* Train your model with training data set\n",
    "* Evaluate your model's performance:\n",
    "    * Interprete model's cross-validation score\n",
    "        * Cross-validate the $R^2$ of an ordinary linear regression model with 10 cross-validation folds.\n",
    "    * Compare the model's train score and test score\n",
    "    * Comment if the model is overfitting and/or underfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate your model\n",
    "linreg = LinearRegression()\n",
    "\n",
    "#Obtain Cross-validation scores\n",
    "\n",
    "#Obtain MEAN Cross-validation score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train your model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train score:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test  score:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment here**\n",
    "\n",
    "What metric is being used here?\n",
    "> Answer: \n",
    "\n",
    "How is the model performance? Interpret the metric score:\n",
    "> Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 5. Find an optimal value for Ridge regression alpha using `RidgeCV`.\n",
    "\n",
    "[Go to the documentation and read how RidgeCV works.](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html)\n",
    "\n",
    "> *Hint: once the RidgeCV is fit, the attribute `.alpha_` contains the best alpha parameter it found through cross-validation.*\n",
    "\n",
    "Recall that Ridge performs best searching alphas through logarithmic space (`np.logspace`). This may take awhile to fit!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgecv ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 6. Evaluate `RidgeCV` model's performance.\n",
    "\n",
    "#### 6a. Cross-validate the Ridge regression $R^2$ with the optimal alpha.\n",
    "\n",
    "Is it better than the Linear regression? If so, why might this be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=ridgecv.alpha_)\n",
    "\n",
    "ridge_scores = \n",
    "\n",
    "print (ridge_scores)\n",
    "print (np.mean(ridge_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's vastly better than the Linear Regression. \n",
    "# There is likely so much multicollinearity in the data that \"vanilla\" regression overfits\n",
    "# and has bogus coefficients on predictors. \n",
    "# Ridge is able to manage the multicollinearity and get a good out-of-sample result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6b. Comment how the model is performing by interpretating its train score and test score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train score:\n",
    "ridge_train_score = \n",
    "ridge_train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test  score:\n",
    "ridge_test_score = \n",
    "ridge_test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment here**\n",
    "\n",
    "How is the model performance? Interpret the metric score:\n",
    "> * The model is much less overfitting than the baseline linear regression model.\n",
    "> * The model has better performance on the test data set, obtaining a test score closer to train score. However, it is still overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 7. Find an optimal value for Ridge regression alpha using RidgeCV\n",
    "\n",
    "Find an optimal value for Lasso regression alpha using `LassoCV`.\n",
    "\n",
    "[Go to the documentation and read how LassoCV works.](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html) It is very similar to `RidgeCV`.\n",
    "\n",
    "> *Hint: again, once the `LassoCV` is fit, the attribute `.alpha_` contains the best alpha parameter it found through cross-validation.*\n",
    "\n",
    "Recall that Lasso, unlike Ridge, performs best searching for alpha through linear space (`np.linspace`). However, you can actually let the LassoCV decide itself what alphas to use by instead setting the keyword argument `n_alphas=` to however many alphas you want it to search over. It is recommended to let sklearn choose the range of alphas.\n",
    "\n",
    "_**Tip:** If you find your CV taking a long time and you're not sure if its working set `verbose =1`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lassocv = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 8. Evaluate `LassoCV` model's performance.\n",
    "#### 8a. Cross-validate the Lasso regression $R^2$ with the optimal alpha.\n",
    "\n",
    "Is it better than the Linear regression? Is it better than Ridge? What do the differences in results imply about the issues with the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=lassocv.alpha_)\n",
    "\n",
    "lasso_scores =\n",
    "\n",
    "print (lasso_scores)\n",
    "print (np.mean(lasso_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8b. Comment how the model is performing by interpretating its train score and test score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train score:\n",
    "lasso_train_score = \n",
    "lasso_train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test  score:\n",
    "lasso_test_score = \n",
    "lasso_test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment here**\n",
    "\n",
    "How is the model performance? Interpret the metric score:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 9. Look at the coefficients for variables in the Lasso.\n",
    "\n",
    "1. Show the coefficient for variables, ordered from largest to smallest coefficient by absolute value.\n",
    "2. What percent of the variables in the original dataset are \"zeroed-out\" by the lasso?\n",
    "3. What are the most important predictors for how many shots Kobe made in a game?\n",
    "\n",
    "> **Note:** if you only fit the Lasso within `cross_val_score`, you will have to refit it outside of that\n",
    "function to pull out the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 10. Find an optimal value for Elastic Net regression alpha using `ElasticNetCV`.\n",
    "\n",
    "[Go to the documentation and read how ElasticNetCV works.](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNetCV.html).\n",
    "\n",
    "Note here that you will be optimizing both the alpha parameter and the l1_ratio:\n",
    "- `alpha`: strength of regularization\n",
    "- `l1_ratio`: amount of ridge vs. lasso (0 = all ridge, 1 = all lasso)\n",
    "    \n",
    "Do not include 0 in the search for `l1_ratio`: it will not allow it and break!\n",
    "\n",
    "You can use `n_alphas` for the alpha parameters instead of setting your own values: highly recommended!\n",
    "\n",
    "Also - be careful setting too many l1_ratios over cross-validation folds in your search. It can take a very long time if you choose too many combinations and for the most part there are diminishing returns in this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimal_enet = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print (optimal_enet.alpha_)\n",
    "print (optimal_enet.l1_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 11. Cross-validate the ElasticNet $R^2$ with the optimal alpha and l1_ratio.\n",
    "\n",
    "How does it compare to the Ridge and Lasso regularized regressions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enet = ElasticNet(alpha=optimal_enet.alpha_,\n",
    "                  l1_ratio=optimal_enet.l1_ratio_)\n",
    "\n",
    "enet_scores = \n",
    "\n",
    "print (enet_scores)\n",
    "print (np.mean(enet_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 12. [Bonus] Compare the residuals for the Ridge and Lasso visually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to fit the ElasticNet and Ridge outside of cross_val_score like i did with the ridge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model residuals:\n",
    "ridge_resid = \n",
    "lasso_resid = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
